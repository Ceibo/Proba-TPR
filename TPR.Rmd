---
title: "Trabajo Práctico Probabilidad y Estadística (c)"
author: "Luis Greco - Nicolas Hertzulis - Ruslan Sanmartin Sobol"
date: "20 de noviembre de 2017"
output:
  pdf_document:
    fig_caption: TRUE
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
---
![Tendencia Probabilistica Revolucionaria](/home/sly/Escritorio/tpr_logo_web2.png)

\pagebreak

Lo primero que vamos a hacer es fijar la semilla de forma global.
```{r, eval=TRUE, echo=TRUE}
set.seed(1109)
```

```{r, eval=TRUE, echo=FALSE}
options(warn=-1)
```


#Ejercicio 1
Acá lo que hicimos fue usar el mismo código visto en clase para generar la exponencial, sólo que en este caso el valor de retorno es la media, por que es lo que necesitabamos.
También podríamos haber usado la función "rexp()".
```{r, eval=TRUE, echo=FALSE}
funcion.inversa <- function(u, lambda){
  sal <- -1*log(1-u)/lambda
  return(sal)
}
Generar.exponenciales_devolviendo_media <- function(n,lambda){
  U <- runif(n)
  sal <- funcion.inversa(U,lambda)
  return(mean(sal))
}
y <- seq(length = 3000)
for (i in 1:3000){
  y[i] <- Generar.exponenciales_devolviendo_media(i, 3)
}
z <- seq(length = 3000)
for (j in 1:3000){
  set.seed(1109)
  z[j] <- Generar.exponenciales_devolviendo_media(j, 3)
}
```

Ahora veamos los gráficos. Este primer gráfico es el que hicimos con el set.seed() "global".
```{r, eval=TRUE, echo=TRUE}
plot(y,col="blue")
```

Este otro, es el que hicimos con el set.seed() dentro de la función.
```{r, eval=TRUE, echo=TRUE}
plot(z,col="red")
```

Nos encontramos con que un gráfico se encuentra notablemente más concentrado sobre ciertos valores que el otro. Creemos que esto se debe a que si fijamos set.seed() localmente dentro de una función, al ejecutarla varias veces, dará siempre el mismo resultado.
Según lo que pudimos encontrar, cuando la función set.seed() es fijada globalmente, al generar números "aleatorios" se empieza usando una secuencia de números desde el subíndice indicado, pero luego las simulaciones siguientes irán cambiando en función de la anterior, o sea que al fijar set.seed() localmente, en cada generación de números no necesariamente tienen que dar iguales.


También pudimos observar el cumplimiento de la Ley de los Grandes Números, al ver que a medida que aumenta el tamaño de la muestra, la media de la misma tiende al valor de la esperanza teórica.

Por lo que explicamos anteriormente sobre el uso de set.seed(), en el segundo gráfico se nota una tendencia muchísimo más marcada.

\pagebreak

#Ejercicio 2

##a)
```{r, eval=TRUE, echo=FALSE}
mediasA <- seq(length=1000)
for (j in 1:1000){
x1 <- rexp(1, rate = 3)
x2 <- rexp(1, rate = 3)
mediasA[j] <- (x1+x2)/2
}
```

```{r, eval=TRUE, echo=TRUE}
hist(mediasA)
```

```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(mediasA)
qqline(mediasA)#La cola del plot
```

Observamos que tanto el histograma, como en el boxplot y q-q plot, los gráficos son asimétricos, lo que es consistente con una distribución exponencial como esta.

\pagebreak

##b)
```{r, eval=TRUE, echo=FALSE}
mediasB <- seq(length = 1000)

for (i in 1:1000){
a <- c(rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3))
mediasB[i] = mean(a)
}
```

```{r, eval=TRUE, echo=TRUE}
hist(mediasB)
```

```{r, eval=TRUE, echo=TRUE}
boxplot(mediasB)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(mediasB)
qqline(mediasB)
```

Se observa que el histograma empieza a tender a una distribucion normal.
En el boxplot pudimos notar colas más pesadas,y por último el Q-Q plot sigue manteniedo una cierta simetría, lo que hace que se vaya pareciendo a una distribución Normal.

\pagebreak

##c)
```{r, eval=TRUE, echo=FALSE}
mediasC1 <- seq(length = 1000) #Acá van con n=30
mediasC2 <-seq(length = 1000) #Acá van con n=500

a <- seq(length = 30)
b <- seq(length = 500)

for (j in 1:1000){
  a <- rexp(30, 3)
  b <- rexp(500, 3)
  mediasC1[j] = mean(a)
  mediasC2[j] = mean(b)
}
```

Con n = 30
```{r, eval=TRUE, echo=TRUE}
hist(mediasC1)
boxplot(mediasC1)
qqnorm(mediasC1)
qqline(mediasC1)
```

Con n = 500
```{r, eval=TRUE, echo=TRUE}
hist(mediasC2)
boxplot(mediasC2)
qqnorm(mediasC2)
qqline(mediasC2)
```
\pagebreak

##d)
Acá nos pareció oportuno adjuntar el gráfico de una distribución normal standard a modo de comparación con los gráficos anteriores, y pudimos notar el cumplimiento de la Ley de los Grandes Números, al ver que a medida que aumentamos el "n" se van pareciendo más a una distrubución normal.

Si aumentaramos más el "n, los gráficos serían aún más parecidos a los de una normal.
Algo similar pudimos observar en los boxplots, en los primeros tres gráficos no se notaba tanto una forma normal, pero con un "n" más grande también lo empezamos a notar y con n = 500 ya podemos decir con seguridad que el boxplot se parece a una normal.

```{r, eval=TRUE, echo=TRUE}
c <- rnorm(1000, 0, 1)
hist(c)
boxplot(c)
qqnorm(c)
qqline(c)
```
\pagebreak

##e)
```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA,mediasB,mediasC1,mediasC2)
```

Obsevamos que a mayor tamaño de la muestra, mayor es su tendencia a una distribucion normal.

En el punto a) poseia colas pesadas, tendiendo a la cola superior y con un número mayor de ouliers. Luego  cada vez que aumentabamos el tamaño de nuestras muestras estos outleirs disminuían y se iban haciendo cada vez más simétricos los boxplots.

En el gráfico no se pueden apreciar con mucho detalle los boxplots correspondientes a los "n" más grandes por la escala, sin embargo ya pudimos ver anteriormente como su forma se correspondía con la de una distribución normal.

\pagebreak

#Ejercicio 3

##a)
Estamos suponiendo que se refiere a la esperanza y varianza muestral.
```{r, eval=TRUE, echo=FALSE}
mediaX1 <- mean(mediasA)
varX1 <- var(mediasA)

mediaX2 <- mean(mediasB)
varX2 <- var(mediasB)

mediaX3 <- mean(mediasC1)
varX3 <- var(mediasC1)


mediaX4 <- mean(mediasC2)
varX4 <- var(mediasC2)
```

```{r, eval=TRUE, echo=TRUE}
mediaX1
varX1


mediaX2
varX2


mediaX3
varX3


mediaX4
varX4
```

##b)
transformacionesA - -->  n = 2

transformacionesB  --->  n = 5

transformacionesC1  --->  n = 30

transformacionesC2  --->  n = 500

```{r, eval=TRUE, echo=FALSE}
esperanzaExp <- 1/3
varianzaExp <- 1/9
transformacionesA <- seq(1000)
for (i in 1:1000){
transformacionesA[i] <- (mediasA[i] - esperanzaExp)/sqrt(varianzaExp/2)
}
transformacionesB <- seq(1000)
for (i in 1:1000){
transformacionesB[i] <- (mediasB[i] - esperanzaExp)/sqrt(varianzaExp/5)
}
transformacionesC1 <- seq(1000)
for (i in 1:1000){
transformacionesC1[i] <- (mediasC1[i] - esperanzaExp)/sqrt(varianzaExp/30)
}
transformacionesC2 <- seq(1000)
for (i in 1:1000){
transformacionesC2[i] <- (mediasC2[i] - esperanzaExp)/sqrt(varianzaExp/500)
}
```

```{r, eval=TRUE, echo=TRUE}
boxplot(transformacionesA, transformacionesB, transformacionesC1, transformacionesC2)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(transformacionesA)
qqline(transformacionesA)

qqnorm(transformacionesB)
qqline(transformacionesB)

qqnorm(transformacionesC1)
qqline(transformacionesC1)

qqnorm(transformacionesC2)
qqline(transformacionesC2)
```

##c)
```{r, eval=TRUE, echo=FALSE}
hist(transformacionesA, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesB, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC1, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC2, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

##d)
En los diferentes histográmas vemos aún con más claridad lo que explicamos en los incisos anteriores sobre como a medida que aumenta el "n", la tendencia de la transformación hacia una normal standard se hace más y más evidente.

\pagebreak

#Ejercicio 4

##Punto 1
```{r, eval=TRUE, echo=FALSE} 
#Podríamos haber hecho:
# y <- rbinom(3000, 5, 1/9)
# Pero como necesitaba el for para poner el set.seed adentro lo dejamos así para que queden iguales.
y <- seq(length = 3000)
for (i in 1:3000){
  y[i] <- rbinom(1, 5, 1/9) 
}

z <- seq(length = 3000)
for (j in 1:3000){
  set.seed(1109)
  z[j] <- mean(rbinom(1, 5, 1/9))
} 

plot(y,col="blue")
plot(z,col="red")
```

Para este punto vale la misma explicación que para la exponencial, con la diferencia que en este caso se trata de una variable discreta.
Debido a esto la diferencia en el gráfico es mucho más brusca, dado que en este caso tenemos un espacio de probabilidad finito y bastante acotado. 

El primer gráfico se corresponde con una binomial de los parametros utilizados, y como al fijar set.seed() dentro de las funciones se repite el mismo experimento se explica que en ese caso el gráfico correspondiente a esa función tenga esa forma de recta.

##Punto 2

###a)
```{r, eval=TRUE, echo=FALSE}
#a)
mediasA <- seq(length=1000)
for (j in 1:1000){
  x1 <- rbinom(2,  5, prob=1/9)
  mediasA[j] <- mean(x1)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma
hist(mediasA)

#Boxplot
boxplot(mediasA)

#Q-Q Plot
qqnorm(mediasA)
qqline(mediasA)#La cola del plot
```
\pagebreak

###b)
```{r, eval=TRUE, echo=FALSE}
mediasB <- seq(length = 1000)

for (i in 1:1000){
  a <- rbinom(5, 5, 1/9)
  mediasB[i] = mean(a)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma
hist(mediasB)

#Boxplot
boxplot(mediasB)

#Q-Q Plot
qqnorm(mediasB)
qqline(mediasB)#La cola del plot
```
\pagebreak

###c)
```{r, eval=TRUE, echo=FALSE}
mediasC1 <- seq(length = 1000) #Acá van con n=30
mediasC2 <-seq(length = 1000) #Acá van con n=500

for (j in 1:1000){
  a <- rbinom(30, 5, 1/9)
  b <- rbinom(500, 5, 1/9)
  mediasC1[j] = mean(a)
  mediasC2[j] = mean(b)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma

hist(mediasC1)

hist(mediasC2)

#Boxplot

boxplot(mediasC1)

boxplot(mediasC2)

#Q-Q Plot
qqnorm(mediasC1)

qqline(mediasC1)#La cola del plot

qqnorm(mediasC2)

qqline(mediasC2)
```

###d)
En el primer punto vemos gráficos que se correponden con una binomial. Al ser una distribución discreta se explica que el Q-Q Plot tenga esa forma escalonada.


Con n = 5 el histograma va adquiriendo una ligera forma de normal, el cambio más notable lo vemos en el boxplot que tiene pocos outliers y brazos relativamente simétricos.


Ahora en los casos de n = 30 podemos ver como todos los gráficos van pareciendose más al de una normal, y más aún cuando n = 500, los gráficos inexorablemente tienen la forma de una distribución normal, la mayor diferencia antes la notabamos en el Q-Q Plot, pero con una muestra de este tamaño ya no queda ninguna duda.
\pagebreak

###e)
```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA,mediasB,mediasC1,mediasC2)
```

Vemos que pasa algo similar a lo que observamos cuando hicimos este mismo experimento con una exponencial, tal vez la mayor diferencia sea que con n = 5 acá ya podemos notar el patrón de una distribución normal. 

##Punto 3

###a)
```{r, eval=TRUE, echo=FALSE}
mediaX1 <- mean(mediasA)
varX1 <- var(mediasA)

mediaX2 <- mean(mediasB)
varX2 <- var(mediasB)

mediaX3 <- mean(mediasC1)
varX3 <- var(mediasC1)

mediaX4 <- mean(mediasC2)
varX4 <- var(mediasC2)
```
```{r, eval=TRUE, echo=TRUE}
#mediaX1
mediaX1
#varX1
varX1

#mediaX2
mediaX2
#varX2
varX2

#mediaX3
mediaX3
#varX3
varX3

#mediaX4
mediaX4
#varX4
varX4
```

###b)
```{r, eval=TRUE, echo=FALSE}
esperanzaBinom <- 5/9
varianzaBinom <- 40/81

transformacionesA <- seq(1000)
for (i in 1:1000){
  transformacionesA[i] <- (mediasA[i] - esperanzaBinom)/sqrt(varianzaBinom/2)
}

transformacionesB <- seq(1000)
for (i in 1:1000){
  transformacionesB[i] <- (mediasB[i] - esperanzaBinom)/sqrt(varianzaBinom/5)
}

transformacionesC1 <- seq(1000)
for (i in 1:1000){
  transformacionesC1[i] <- (mediasC1[i] - esperanzaBinom)/sqrt(varianzaBinom/30)
}

transformacionesC2 <- seq(1000)
for (i in 1:1000){
  transformacionesC2[i] <- (mediasC2[i] - esperanzaBinom)/sqrt(varianzaBinom/500)
}
```
```{r, eval=TRUE, echo=TRUE}
boxplot(transformacionesA, transformacionesB, transformacionesC1, transformacionesC2)

qqnorm(transformacionesA)
qqline(transformacionesA)

qqnorm(transformacionesB)
qqline(transformacionesB)

qqnorm(transformacionesC1)
qqline(transformacionesC1)

qqnorm(transformacionesC2)
qqline(transformacionesC2)
```

###c)
```{r, eval=TRUE, echo=FALSE}
hist(transformacionesA, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesB, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC1, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC2, freq = FALSE)
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```
\pagebreak

###d)
Observamos lo mismo que al llevar a cabo este ejercicio con la exponencial.
Anteriormente vimos como la binomial tendía a una normal por la Ley de los Grandes Números, y ahora vimos como gracias a las propiedades de la distribución normal pudimos aplicar esta transformación y obtener algo que tiende aproximadamente a una distribución normal standard.
