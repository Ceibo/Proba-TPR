---
title: "Trabajo Práctico Probabilidad y Estadística (c)"
author: "Luis Greco - Nicolas Hertzulis - Ruslan Sanmartin Sobol"
date: "20 de noviembre de 2017"
output:
  pdf_document:
    fig_caption: TRUE
    toc: true # table of content true
    toc_depth: 3  # upto three depths of headings (specified by #, ## and ###)
---
![Tendencia Probabilistica Revolucionaria](/home/sly/Desktop/tpr_logo_web2.png)


Lo primero que vamos a hacer es fijar la semilla de forma global.
```{r, eval=TRUE, echo=TRUE}
set.seed(1109)
```

```{r, eval=TRUE, echo=FALSE}
options(warn=-1)
```


#Ejercicio 1
Acá lo que hicimos fue usar el mismo código visto en clase para generar la exponencial, sólo que en este caso el valor de retorno es la media, por que es lo que necesitabamos.
También podríamos haber usado la función "rexp()".
```{r, eval=TRUE, echo=FALSE}
funcion.inversa <- function(u, lambda){
  sal <- -1*log(1-u)/lambda
  return(sal)
}
Generar.exponenciales_devolviendo_media <- function(n,lambda){
  U <- runif(n)
  sal <- funcion.inversa(U,lambda)
  return(mean(sal))
}
y <- seq(length = 3000)
for (i in 1:3000){
  y[i] <- Generar.exponenciales_devolviendo_media(i, 3)
}
z <- seq(length = 3000)
for (j in 1:3000){
  set.seed(1109)
  z[j] <- Generar.exponenciales_devolviendo_media(j, 3)
}
```

Ahora veamos los gráficos. Este primer gráfico es el que hicimos con el set.seed() "global".
```{r, eval=TRUE, echo=TRUE}
plot(y,col="blue")
```

Este otro, es el que hicimos con el set.seed() dentro de la función.
```{r, eval=TRUE, echo=TRUE}
plot(z,col="red")
```

Nos encontramos con que un gráfico se encuentra notablemente más concentrado sobre ciertos valores que el otro. Creemos que esto se debe a que si fijamos set.seed() localmente dentro de una función, al ejecutarla varias veces, dará siempre el mismo resultado.
Según lo que pudimos encontrar, cuando la función set.seed() es fijada globalmente, al generar números "aleatorios" se empieza usando una secuencia de números desde el subíndice indicado, pero luego las simulaciones siguientes irán cambiando en función de la anterior, o sea que al fijar set.seed() localmente, en cada generación de números no necesariamente tienen que dar iguales.


También pudimos observar el cumplimiento de la Ley de los Grandes Números, al ver que a medida que aumenta el tamaño de la muestra, la media de la misma tiende al valor de la esperanza teórica.

Por lo que explicamos anteriormente sobre el uso de set.seed(), en el segundo gráfico se nota una tendencia muchísimo más marcada.

#Ejercicio 2

##a)
```{r, eval=TRUE, echo=FALSE}
mediasA <- seq(length=1000)
for (j in 1:1000){
x1 <- rexp(1, rate = 3)
x2 <- rexp(1, rate = 3)
mediasA[j] <- (x1+x2)/2
}
```

```{r, eval=TRUE, echo=TRUE}
hist(mediasA)
```

```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(mediasA)
qqline(mediasA)#La cola del plot
```

Observamos que tanto el histograma, como en el boxplot y q-q plot, los gráficos son asimétricos, lo que es consistente con una distribución exponencial como esta.

##b)
```{r, eval=TRUE, echo=FALSE}
mediasB <- seq(length = 1000)

for (i in 1:1000){
a <- c(rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3), rexp(1, rate = 3))
mediasB[i] = mean(a)
}
```

```{r, eval=TRUE, echo=TRUE}
hist(mediasB)
```

```{r, eval=TRUE, echo=TRUE}
boxplot(mediasB)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(mediasB)
qqline(mediasB)
```

Se observa que el histograma empieza a tender a una distribucion normal.
En el boxplot pudimos notar colas más pesadas,y por último el Q-Q plot sigue manteniedo una cierta simetría, lo que hace que se vaya pareciendo a una distribución Normal.

##c)
```{r, eval=TRUE, echo=FALSE}
mediasC1 <- seq(length = 1000) #Acá van con n=30
mediasC2 <-seq(length = 1000) #Acá van con n=500

a <- seq(length = 30)
b <- seq(length = 500)

for (j in 1:1000){
  a <- rexp(30, 3)
  b <- rexp(500, 3)
  mediasC1[j] = mean(a)
  mediasC2[j] = mean(b)
}
```

Con n = 30
```{r, eval=TRUE, echo=TRUE}
hist(mediasC1)
boxplot(mediasC1)
qqnorm(mediasC1)
qqline(mediasC1)
```

Con n = 500
```{r, eval=TRUE, echo=TRUE}
hist(mediasC2)
boxplot(mediasC2)
qqnorm(mediasC2)
qqline(mediasC2)
```

##d)
Acá tenemos los gráficos de una Normal(0,1) a modo de comparación con los gráficos anteriores, y notamos que como se cumple la Ley de los Grandes Números, al ver que a medida que aumentamos el "n" se van pareciendo más a una distrubución normal.

Si aumentaramos todavía más el n, los gráficos serían aún más parecidos a los de una normal.
Algo parecido pudimos observar en los boxplots, que en los primeros tres gráficos no se notaba tanto una forma normal, pero con un n más grande también lo empezamos a notar y ahora podemos decír que el boxplot se parece a una normal.

```{r, eval=TRUE, echo=TRUE}
c <- rnorm(1000, 0, 1)
hist(c)
boxplot(c)
qqnorm(c)
qqline(c)
```

##e)
```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA,mediasB,mediasC1,mediasC2)
```

Obsevamos que con mayor muestra se puede verificar su tendencia a una distribucion normal.
Dado que en el punto a, presuponia que poseia colas pesadas, tendiendo a la cola superior, con bastantes ouliers, siendo que cada vez que aumentabamos las muestras estos outleirs disminuian y las colas pesadas tendian a desaparecer y tender cada vez mas a la normal.


#Ejercicio 3

##a)
Estamos suponiendo que se refiere a la esperanza y varianza muestral.
```{r, eval=TRUE, echo=FALSE}
mediaX1 <- mean(mediasA)
varX1 <- var(mediasA)

mediaX2 <- mean(mediasB)
varX2 <- var(mediasB)

mediaX3 <- mean(mediasC1)
varX3 <- var(mediasC1)


mediaX4 <- mean(mediasC2)
varX4 <- var(mediasC2)
```

```{r, eval=TRUE, echo=TRUE}
mediaX1
varX1


mediaX2
varX2


mediaX3
varX3


mediaX4
varX4
```

##b)
transformacionesA -> n = 2

transformacionesB -> n = 5

transformacionesC1 -> n = 30

transformacionesC2 -> n = 500

```{r, eval=TRUE, echo=FALSE}
esperanzaExp <- 1/3
varianzaExp <- 1/9
transformacionesA <- seq(1000)
for (i in 1:1000){
transformacionesA[i] <- (mediasA[i] - esperanzaExp)/sqrt(varianzaExp/2)
}
transformacionesB <- seq(1000)
for (i in 1:1000){
transformacionesB[i] <- (mediasB[i] - esperanzaExp)/sqrt(varianzaExp/5)
}
transformacionesC1 <- seq(1000)
for (i in 1:1000){
transformacionesC1[i] <- (mediasC1[i] - esperanzaExp)/sqrt(varianzaExp/30)
}
transformacionesC2 <- seq(1000)
for (i in 1:1000){
transformacionesC2[i] <- (mediasC2[i] - esperanzaExp)/sqrt(varianzaExp/500)
}
```

```{r, eval=TRUE, echo=TRUE}
boxplot(transformacionesA, transformacionesB, transformacionesC1, transformacionesC2)
```

```{r, eval=TRUE, echo=TRUE}
qqnorm(transformacionesA)
qqline(transformacionesA)

qqnorm(transformacionesB)
qqline(transformacionesB)

qqnorm(transformacionesC1)
qqline(transformacionesC1)

qqnorm(transformacionesC2)
qqline(transformacionesC2)
```

##c)
```{r, eval=TRUE, echo=FALSE}
hist(transformacionesA, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesB, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC1, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC2, freq = FALSE, col = "grey", xlim = c(-3.5, 3.5))
curve(dnorm(x, mean = 0, sd = 1), add = TRUE, col = "darkblue", lwd = 2)
```

##d)
En los diferentes histográmas vemos aún con más claridad lo que explicamos en los incisos anteriores sobre como a medida que aumenta el "n", la tendencia de la transformación hacia una normal standard se hace más y más evidente.

#Ejercicio 4

##Punto 1
```{r, eval=TRUE, echo=FALSE} 
#Podríamos haber hecho:
# y <- rbinom(3000, 5, 1/9)
# Pero como necesitaba el for para poner el set.seed adentro lo dejamos así para que queden iguales.
y <- seq(length = 3000)
for (i in 1:3000){
  y[i] <- rbinom(1, 5, 1/9) 
}

z <- seq(length = 3000)
for (j in 1:3000){
  set.seed(1109)
  z[j] <- mean(rbinom(1, 5, 1/9))
} 

plot(y,col="blue")
plot(z,col="red")
```

Para este punto vale la misma explicación que para la exponencial, con la diferencia que en este caso se trata de una variable discreta.

Debido a esto la diferencia en el gráfico es mucho más brusca, dado que en este caso tenemos un espacio de probabilidad finito y bastante acotado. 

El primer gráfico se corresponde con una binomial de los parametros utilizados, y como al fijar set.seed() dentro de las funciones se repite el mismo experimento se explica que en ese caso el gráfico correspondiente a esa funciómn tenga esa forma de recta.

##Punto 2

###a)
```{r, eval=TRUE, echo=FALSE}
#a)
mediasA <- seq(length=1000)
for (j in 1:1000){
  x1 <- rbinom(2,  5, prob=1/9)
  mediasA[j] <- mean(x1)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma
hist(mediasA)

#Boxplot
boxplot(mediasA)

#Q-Q Plot
qqnorm(mediasA)
qqline(mediasA)#La cola del plot
```

Del histograma se obveserva simetria de las colas livianas.
En el Q-Q plot se observa una simetria de las colas livianas.
Se observa que el boxplot tiende a una normal.

###b)
```{r, eval=TRUE, echo=FALSE}
mediasB <- seq(length = 1000)

for (i in 1:1000){
  a <- rbinom(5, 5, 1/9)
  mediasB[i] = mean(a)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma
hist(mediasB)

#Boxplot
boxplot(mediasB)

#Q-Q Plot
qqnorm(mediasB)
qqline(mediasB)#La cola del plot
```

Se observa que el histograma simetria de las colas livianas es mas fuerte.
El boxplot es una "perfecta" normal y el Q-Q plot sigue manteniedo la  simetria de las colas livianas.

###c)
```{r, eval=TRUE, echo=FALSE}
mediasC1 <- seq(length = 1000) #Acá van con n=30
mediasC2 <-seq(length = 1000) #Acá van con n=500

for (j in 1:1000){
  a <- rbinom(30, 5, 1/9)
  b <- rbinom(500, 5, 1/9)
  mediasC1[j] = mean(a)
  mediasC2[j] = mean(b)
}
```
```{r, eval=TRUE, echo=TRUE}
#Histograma

hist(mediasC1)

hist(mediasC2)

#Boxplot

boxplot(mediasC1)

boxplot(mediasC2)

#Q-Q Plot
qqnorm(mediasC1)

qqline(mediasC1)#La cola del plot

qqnorm(mediasC2)

qqline(mediasC2)
```

###d)
```{r, eval=TRUE, echo=FALSE}
c <- rnorm(1000, 0, 1)
```

```{r, eval=TRUE, echo=TRUE}
hist(c)
```
```{r, eval=TRUE, echo=TRUE}
boxplot(c)
```
```{r, eval=TRUE, echo=TRUE}
qqnorm(c)
qqline(c)
```

Se nota con muchas mas fuerza en el histograma la distribucion normal.
Lo mismo con el boxplot, el cual era el unico hasta el momento que no parecia tender a la normal. Ahora con una gran seguridad podemos confirmar que tiene a una normal con muy pocos outliers.
Y el Q-Qplot se aferra con mucha mas fuerza a una distribucion normal.

###e)
```{r, eval=TRUE, echo=TRUE}
boxplot(mediasA,mediasB,mediasC1,mediasC2,c)
```

Obsevamos que con una menor muestra se puede verificar su tendencia a una distribucion normal.
Si aumentamos el n, el boxplot empieza a tener colas pesadas y deja de tender a una normal.


##Punto 3

###a)
```{r, eval=TRUE, echo=FALSE}
mediaX1 <- mean(mediasA)
varX1 <- var(mediasA)

mediaX2 <- mean(mediasB)
varX2 <- var(mediasB)

mediaX3 <- mean(mediasC1)
varX3 <- var(mediasC1)

mediaX4 <- mean(mediasC2)
varX4 <- var(mediasC2)
```
```{r, eval=TRUE, echo=TRUE}
#mediaX1
mediaX1
#varX1
varX1

#mediaX2
mediaX2
#varX2
varX2

#mediaX3
mediaX3
#varX3
varX3

#mediaX4
mediaX4
#varX4
varX4
```

###b)
```{r, eval=TRUE, echo=FALSE}
esperanzaBinom <- 5/9
varianzaBinom <- 40/81

transformacionesA <- seq(1000)
for (i in 1:1000){
  transformacionesA[i] <- (mediasA[i] - esperanzaBinom)/sqrt(varianzaBinom/2)
}

transformacionesB <- seq(1000)
for (i in 1:1000){
  transformacionesB[i] <- (mediasB[i] - esperanzaBinom)/sqrt(varianzaBinom/5)
}

transformacionesC1 <- seq(1000)
for (i in 1:1000){
  transformacionesC1[i] <- (mediasC1[i] - esperanzaBinom)/sqrt(varianzaBinom/30)
}

transformacionesC2 <- seq(1000)
for (i in 1:1000){
  transformacionesC2[i] <- (mediasC2[i] - esperanzaBinom)/sqrt(varianzaBinom/500)
}
```
```{r, eval=TRUE, echo=TRUE}
boxplot(transformacionesA, transformacionesB, transformacionesC1, transformacionesC2)

qqnorm(transformacionesA)
qqline(transformacionesA)

qqnorm(transformacionesB)
qqline(transformacionesB)

qqnorm(transformacionesC1)
qqline(transformacionesC1)

qqnorm(transformacionesC2)
qqline(transformacionesC2)
```

###c)
```{r, eval=TRUE, echo=FALSE}
hist(transformacionesA, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesB, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC1, freq = FALSE, xlim = c(-3, 3))
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

```{r, eval=TRUE, echo=FALSE}
hist(transformacionesC2, freq = FALSE)
curve(dnorm(x, mean=0, sd=1), add=TRUE, col="darkblue", lwd=2)
```

Se observa en el histograma `mediasA` y en `mediasB`, poseen una asimetria a la derecha, dado a que la muestra parece no ser lo suficientemente grande, lo cual no nos da informacion respecto a si tiende a una normal.

En los últimos gráficos notamos que a medida que el n se va agrandando, se va pareciendo más a una normal, sin embargo no se parece tanto como creemos que tendría que pasar, ya que no aproxima a una normal standard.

Creemos que esto se debe a algún error en nuestro código al momento de hacer la transformación o al usar la función rbinom.
